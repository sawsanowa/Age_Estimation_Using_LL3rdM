{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-unet-collection\n",
        "#!pip install focal-loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2oxUNkNF-kH",
        "outputId": "f13908a3-35c9-4e09-ab09-70cdee2c19bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-unet-collection in /usr/local/lib/python3.7/dist-packages (0.1.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHeIZsiubgGx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow_hub as hub\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow import keras\n",
        "from keras_unet_collection import models, losses\n",
        "#from focal_loss import BinaryFocalLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fU9iWgU2MZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a50e488-7d12-45b6-a713-bb46b9684237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcrUiwz-DTk8"
      },
      "outputs": [],
      "source": [
        "#pre-processing and check all images and masks correctly read\n",
        "IMG_WIDTH = 512\n",
        "IMG_HEIGHT = 256\n",
        "IMG_CHANNELS = 1\n",
        " \n",
        "DATA_PATH = '/Path--/images/' # Training original images\n",
        "Mask_path1= '/Path--/masks/'  # Segmentation Map\n",
        "\n",
        "\n",
        "seed = 42\n",
        "random.seed = seed\n",
        "np.random.seed = seed\n",
        " \n",
        "image_ids = next(os.walk(DATA_PATH))[2]\n",
        "\n",
        "len(image_ids)\n",
        "X = np.zeros((len(image_ids), IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)\n",
        "Y = np.zeros((len(image_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
        "\n",
        "print('resizing training images and masks')\n",
        "for n, id_ in tqdm(enumerate(image_ids), total=len(image_ids)):\n",
        "  try:\n",
        "    path = DATA_PATH \n",
        "    img = imread(path+ id_)[:,:]\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X[n] = img\n",
        "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
        "    for mask_file in next(os.walk(Mask_path1))[2]:\n",
        "      if mask_file==id_:\n",
        "        #print(Mask_path1 +  mask_file)\n",
        "        mask_ = imread(Mask_path1 + mask_file)\n",
        "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',\n",
        "                                      preserve_range=True), axis=-1)\n",
        "        mask = np.maximum(mask, mask_)\n",
        "\n",
        "    Y[n] = mask\n",
        "  except:\n",
        "    print('error')\n",
        "\n",
        "x_train=X \n",
        "y_train=Y\n",
        "\n",
        "print('Done!')\n",
        "\n",
        "image_x = random.randint(0, len(image_ids))\n",
        "imshow(x_train[image_x])\n",
        "plt.show()\n",
        "imshow(np.squeeze(y_train[image_x])+1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e6o-T9xSBEw",
        "outputId": "62c88b5e-99fd-4bbb-93f0-c7f617e0f774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resizing training images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [00:29<00:00,  4.07it/s]\n"
          ]
        }
      ],
      "source": [
        "#test images\n",
        "TEST_PATH = '/Path--/images/'\n",
        "\n",
        "test_ids = next(os.walk(TEST_PATH))[2]\n",
        "\n",
        "len(test_ids)\n",
        "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)\n",
        "\n",
        "sizes_test=[]\n",
        "print('resizing training images')\n",
        "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "  path = TEST_PATH \n",
        "  img = imread(path+ id_)[:,:]\n",
        "  sizes_test.append([img.shape[0],img.shape[1]])\n",
        "  img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "  X_test[n]=img "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viXupPEvK1yq"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaWnBqIJebcL"
      },
      "outputs": [],
      "source": [
        "#Build U-Net model\n",
        "\n",
        "# Input layer\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "\n",
        "# Contraction path\n",
        "c1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "c1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\n",
        "\n",
        "c2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "c2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\n",
        "\n",
        "c3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "c3 = tf.keras.layers.Dropout(0.1)(c3)\n",
        "c3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\n",
        "\n",
        "c4 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "c4 = tf.keras.layers.Dropout(0.1)(c4)\n",
        "c4 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "p4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\n",
        "\n",
        "c5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "c5 = tf.keras.layers.Dropout(0.1)(c5)\n",
        "c5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "#Expansive path\n",
        "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "c6 = tf.keras.layers.Dropout(0.1)(c6)\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "c7 = tf.keras.layers.Dropout(0.1)(c7)\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        " \n",
        "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        " \n",
        "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        " \n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "#opt = keras.optimizers.Adam(learning_rate=0.00001)\n",
        "#model.compile(optimizer='adam', loss=[BinaryFocalLoss(gamma=2,label_smoothing=0.1,pos_weight=.25)], metrics=['accuracy', losses.dice_coef])\n",
        "#model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0.0), metrics=['accuracy', losses.dice_coef])\n",
        "model.compile(optimizer='adam', loss='BinaryCrossentropy', metrics=['accuracy', losses.dice_coef])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "VViqvyUYW-G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzD4XRXRepc_"
      },
      "outputs": [],
      "source": [
        "#Modelcheckpoint-> save model after every epoch\n",
        "#save_best_only -> the latest best model will not be overwritten \n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint('/content/model_3m.h5', verbose=1, save_best_only=True)\n",
        "callbacks= [\n",
        "            tf.keras.callbacks.EarlyStopping(patience=5, monitor='loss'),\n",
        "            tf.keras.callbacks.TensorBoard(log_dir='./logs2')]\n",
        "results = model.fit(x_train,y_train, batch_size=10, epochs=50, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPA4IjWWpTXs"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxAjhzL5X0VI"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTKxOCCqjPk0"
      },
      "outputs": [],
      "source": [
        "#Save weights only\n",
        "model.save_weights('/content/unet_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRCOPTAWDigI"
      },
      "outputs": [],
      "source": [
        "#Save model\n",
        "t = time.time()\n",
        "my_keras_model_filepath = '/content/unet_model.h5'.format(int(t))\n",
        "print(my_keras_model_filepath)\n",
        "model.save(my_keras_model_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lihJKZv7XSVl"
      },
      "outputs": [],
      "source": [
        "training_loss=results.history['loss']\n",
        "training_accuracy=results.history['accuracy']\n",
        "#validation_loss=results.history['val_loss']\n",
        "#validation_accuracy=results.history['val_accuracy']\n",
        "\n",
        "epochs_range=range(len(training_accuracy))\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, training_accuracy, label='Training Accuracy')\n",
        "#plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "#plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, training_loss, label='Training Loss')\n",
        "#plt.plot(epochs_range, validation_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1rCqjpqxSzj"
      },
      "outputs": [],
      "source": [
        "idx = random.randint(0, len(x_train))\n",
        "preds_train = model.predict(x_train[:int(x_train.shape[0]*0.9)], verbose=1)\n",
        "#preds_val = model.predict(x_train[int(x_train.shape[0]*0.9):], verbose=1)\n",
        "preds_test = model.predict(X_test, verbose=1)\n",
        "\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "#preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dli3Y-5hljdD"
      },
      "outputs": [],
      "source": [
        "# Perform a sanity check on some random training samples\n",
        "ix = random.randint(0, len(preds_train_t))\n",
        "imshow(x_train[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(y_train[ix])+1)\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_train_t[ix]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMxY3kwsltwC"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# Perform a sanity check on some random validation samples\n",
        "ix = random.randint(0, len(preds_val_t))\n",
        "imshow(x_train[int(x_train.shape[0]*0.9):][ix]-1)\n",
        "plt.show()\n",
        "imshow(np.squeeze(y_train[int(y_train.shape[0]*0.9):][ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_val_t[ix]))\n",
        "plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nFRtlBJq_Yl"
      },
      "outputs": [],
      "source": [
        "test_paths = os.listdir(TEST_PATH)\n",
        "print(len(test_paths), 'test images found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kX7bL75hl02c"
      },
      "outputs": [],
      "source": [
        "#testing with test set\n",
        "ix = random.randint(0, len(preds_test_t))\n",
        "imshow(X_test[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_test_t[ix]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5XuZDa_hPDe"
      },
      "source": [
        "# Support References:\n",
        "\n",
        "\n",
        "*   https://stackoverflow.com/questions/10989005/do-i-understand-os-walk-right\n",
        "*   https://www.youtube.com/watch?v=68HR_eyzk00&t=938s \n",
        "*   https://www.youtube.com/watch?v=RaswBvMnFxk\n",
        "*   https://github.com/bnsreenu/python_for_microscopists/blob/master/074-Defining%20U-net%20in%20Python%20using%20Keras.py\n",
        "* https://www.youtube.com/watch?v=kaE7jQqIFI8\n",
        "* https://github.com/bnsreenu/python_for_microscopists/blob/master/076-077-078-Unet_nuclei_tutorial.py\n",
        "* https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb#scrollTo=8p3Tbx8cWEFA\n",
        "* https://focal-loss.readthedocs.io/en/latest/\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Unet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention_UNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-unet-collection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgTbkeWdPxcJ",
        "outputId": "e48d1a03-0d59-40bb-b03d-d0d1c936a7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-unet-collection\n",
            "  Downloading keras_unet_collection-0.1.13-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 2.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: keras-unet-collection\n",
            "Successfully installed keras-unet-collection-0.1.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHeIZsiubgGx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow_hub as hub\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_unet_collection import models, losses\n",
        "from datetime import datetime "
      ],
      "metadata": {
        "id": "UbBAvqBDND0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fU9iWgU2MZp",
        "outputId": "6f142580-264e-4bf1-8186-9134ce48f6e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcrUiwz-DTk8"
      },
      "outputs": [],
      "source": [
        "#pre-processing and check all images and masks correctly read\n",
        "IMG_WIDTH = 512\n",
        "IMG_HEIGHT = 256\n",
        "IMG_CHANNELS = 1\n",
        " \n",
        "DATA_PATH = '/Path--/images/' # Training original images\n",
        "Mask_path1= '/Path--/masks/'   # Segmentation Map\n",
        "\n",
        "\n",
        "\n",
        "seed = 42\n",
        "random.seed = seed\n",
        "np.random.seed = seed\n",
        " \n",
        "image_ids = next(os.walk(DATA_PATH))[2]\n",
        "\n",
        "len(image_ids)\n",
        "X = np.zeros((len(image_ids), IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)\n",
        "Y = np.zeros((len(image_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
        "\n",
        "print('resizing training images and masks')\n",
        "for n, id_ in tqdm(enumerate(image_ids), total=len(image_ids)):\n",
        "  try:\n",
        "    path = DATA_PATH \n",
        "    img = imread(path+ id_)[:,:]\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X[n] = img\n",
        "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
        "    for mask_file in next(os.walk(Mask_path1))[2]:\n",
        "      if mask_file==id_:\n",
        "        #print(Mask_path1 +  mask_file)\n",
        "        mask_ = imread(Mask_path1 + mask_file)\n",
        "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',\n",
        "                                      preserve_range=True), axis=-1)\n",
        "        mask = np.maximum(mask, mask_)\n",
        "\n",
        "    Y[n] = mask\n",
        "  except:\n",
        "    print('error')\n",
        "\n",
        "x_train=X \n",
        "y_train=Y\n",
        "\n",
        "print('Done!')\n",
        "\n",
        "image_x = random.randint(0, len(image_ids))\n",
        "imshow(x_train[image_x])\n",
        "plt.show()\n",
        "imshow(np.squeeze(y_train[image_x])+1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e6o-T9xSBEw"
      },
      "outputs": [],
      "source": [
        "#test images\n",
        "TEST_PATH = '/Path--/images/'\n",
        "\n",
        "test_ids = next(os.walk(TEST_PATH))[2]\n",
        "\n",
        "len(test_ids)\n",
        "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)\n",
        "\n",
        "sizes_test=[]\n",
        "print('resizing training images')\n",
        "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "  path = TEST_PATH \n",
        "  img = imread(path+ id_)[:,:]\n",
        "  sizes_test.append([img.shape[0],img.shape[1]])\n",
        "  img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "  X_test[n]=img "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 1  #Binary\n",
        "input_shape = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)\n",
        "batch_size = 10"
      ],
      "metadata": {
        "id": "58JkEPd4Pwle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(models.att_unet_2d)"
      ],
      "metadata": {
        "id": "sNriUggKQn1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_att_unet = models.att_unet_2d((256, 512, 1), filter_num=[16,32,64, 128, 256], \n",
        "                           n_labels=num_labels, \n",
        "                           stack_num_down=2, stack_num_up=2, \n",
        "                           activation='ReLU', \n",
        "                           atten_activation='ReLU', attention='add', \n",
        "                           output_activation='Sigmoid', \n",
        "                           batch_norm=True, pool=True, unpool=True, \n",
        "                           backbone=None, weights=None, \n",
        "                           freeze_backbone=False, freeze_batch_norm=False, \n",
        "                           name='attunet')\n",
        "\n",
        "\n",
        "model_att_unet.compile(loss='binary_crossentropy', optimizer='adam', \n",
        "              metrics=['accuracy',losses.dice_coef])\n",
        "\n",
        "print(model_att_unet.summary())"
      ],
      "metadata": {
        "id": "gbmV0NX5QkN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start3 = datetime.now() \n",
        "callbacks= [tf.keras.callbacks.EarlyStopping(patience=5, monitor='loss')]#val_loss\n",
        "att_unet_history = model_att_unet.fit(x_train, y_train, \n",
        "                    verbose=1,\n",
        "                    batch_size = batch_size,\n",
        "                    #validation_split=0.2, \n",
        "                    shuffle=False,\n",
        "                    epochs=50, callbacks=callbacks)\n",
        "\n",
        "stop3 = datetime.now()\n",
        "#Execution time of the model \n",
        "execution_time_att_Unet = stop3-start3\n",
        "print(\"Attention UNet execution time is: \", execution_time_att_Unet)"
      ],
      "metadata": {
        "id": "HBtTkaQyQ-Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = time.time()\n",
        "my_keras_model_filepath = '3rdm_att_UNet_50epochs_acc.h5'.format(int(t))\n",
        "print(my_keras_model_filepath)\n",
        "model_att_unet.save(my_keras_model_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lppGeC2aLbFe",
        "outputId": "41bf729b-53c4-4749-fd12-73f5147acf5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3rdm_att_UNet_50epochs_acc.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "att_unet_history_df = pd.DataFrame(att_unet_history.history) "
      ],
      "metadata": {
        "id": "_4v2yhCSR3-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('att_unet_history_df.csv', mode='w') as f:\n",
        "    att_unet_history_df.to_csv(f) "
      ],
      "metadata": {
        "id": "qpzBZj9aSV-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = att_unet_history"
      ],
      "metadata": {
        "id": "C-KWmFhqSa21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "#val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "#plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['dice_coef']\n",
        "#acc = history.history['accuracy']\n",
        "#val_acc = history.history['val_dice_coef']\n",
        "#val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training Dice')\n",
        "#plt.plot(epochs, val_acc, 'r', label='Validation Dice')\n",
        "plt.title('Training and validation Dice')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Dice')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WfeqUZmGSe8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_att_unet"
      ],
      "metadata": {
        "id": "Nh-OVPfKSp-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = random.randint(0, len(x_train))\n",
        "preds_train = model_att_unet.predict(x_train[:int(x_train.shape[0]*0.9)], verbose=1)\n",
        "preds_val = model_att_unet.predict(x_train[int(x_train.shape[0]*0.9):], verbose=1)\n",
        "preds_test = model_att_unet.predict(X_test, verbose=1)\n",
        "\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
      ],
      "metadata": {
        "id": "xrUpMweBM33Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ix = random.randint(0, len(preds_test_t))\n",
        "imshow(X_test[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_test_t[ix]))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n6PtpQw0MsW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Support References:\n",
        "\n",
        "\n",
        "*   https://github.com/bnsreenu/python_for_microscopists/blob/master/227_mito_segm_using_models_from_Keras_Unet_collection.py\n",
        "*   https://pypi.org/project/keras-unet-collection/\n",
        "*   https://github.com/yingkaisha/keras-unet-collection/blob/main/examples/user_guide_models.ipynb\n",
        "*   https://www.youtube.com/watch?v=ZoJuhRbzEiM\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yl8wIq0ubsuM"
      }
    }
  ]
}